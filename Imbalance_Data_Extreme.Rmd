---
title: "Exploratory Data Analysis"
output: html_document
date: "2023-11-08"
---

```{r}
df <- read.csv("OriginalData.csv")
```

```{r}
library(tidyverse)
library(caret)
library(pROC)
library("MLmetrics")
library("ROSE")
library(dplyr)
library("lubridate")
```


```{r}
# Separate positive and negative classes
true_class <- df %>% filter(Arrest == "true")
false_class <- df %>% filter(Arrest == "false")

# Set the desired ratio of positive to negative samples
desired_positive_ratio <- 0.05

# Calculate the number of positive samples needed for downsampling
num_true_samples <- 0.05*nrow(false_class) / (1 - desired_positive_ratio)

# Randomly sample positive samples
true_class_downsampled <- true_class %>% sample_n(num_true_samples, replace = FALSE, seed = 42)

# Combine positive and downsampled negative samples
downsampled_dataset <- bind_rows(false_class, true_class_downsampled)

# Shuffle the dataset to mix positive and negative samples
set.seed(42)
downsampled_dataset <- downsampled_dataset[sample(nrow(downsampled_dataset)), ]

sum(downsampled_dataset[,"Arrest"]=="true")/dim(df)[1]
```

```{r}
downsampled_dataset$Date <- mdy_hms(downsampled_dataset$Date)
```


```{r}
library("magrittr")
downsampled_dataset %<>% mutate(day=yday(Date))  %<>% mutate(hr=as.numeric(hour(Date))) %>% drop_na(X.Coordinate)
downsampled_dataset$X.Coordinate <- as.numeric(downsampled_dataset$X.Coordinate)
downsampled_dataset$Y.Coordinate <- as.numeric(downsampled_dataset$Y.Coordinate)
downsampled_dataset$Primary.Type <- as.factor(downsampled_dataset$Primary.Type)
```




```{r}
#make this example reproducible
set.seed(1)

#use 80% of dataset as training set and 30% as test set 
train <- downsampled_dataset %>% dplyr::sample_frac(0.80)
train$Arrest <- as.factor(train$Arrest)
test  <- dplyr::anti_join(downsampled_dataset, train, by = 'ID')
test$Arrest <- as.factor(test$Arrest)
```


```{r}
#train$Arrest <- make.names(train$Arrest)
```


## 5 fold cross-validation on train set
```{r}
ctrl <- trainControl(method = "cv", number = 5, summaryFunction = twoClassSummary, classProbs = TRUE)
```


```{r}
log_reg0 <- train(Arrest ~ X.Coordinate + Y.Coordinate + day + hr + 
    Primary.Type, data = train, method = "glm", family = "binomial", trControl = ctrl, metric = "ROC")
```



```{r}
print(log_reg0)
```


```{r}
pred_p <- predict(log_reg0, test[,c("X.Coordinate", "Y.Coordinate", "day", "hr", "Primary.Type")], type = "prob")
```

```{r}
# Create a ROC curve object
roc_curve <- roc(test$Arrest, pred_p[, "true"])

# Plot the ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)

# Add AUC to the plot
auc_value <- auc(roc_curve)
text(0.8, 0.2, paste("AUC =", round(auc_value, 3)), col = "blue", cex = 1.2)
```

```{r}
binary_predictions <- ifelse(pred_p[,2] >= 0.5, "true", "false")
#sum(binary_predictions==1)
# create confusion matrix 
confusionMatrix(as.factor(binary_predictions), test$Arrest,
                mode = "everything",
                positive="true")
```

```{r}
f_beta_score <- function(data, model, beta) {
  predictions <- predict(model, data[,c("X.Coordinate", "Y.Coordinate", "day", "hr", "Primary.Type")], type = "prob")[,2]
  threshold <- 0.5  # You can adjust this threshold based on your needs
  predicted_classes <- ifelse(predictions > threshold, "true", "false")
  predicted_classes <- as.factor(predicted_classes)
  pr <- confusionMatrix(data = predicted_classes, reference = data$Arrest, 
                        mode = "everything", positive="true")

  precision <- as.numeric(pr$byClass["Precision"])
  recall <- as.numeric(pr$byClass["Recall"])

  f_beta <- ((1 + beta^2) * precision * recall) / (beta^2 * precision + recall)
  return(f_beta)
}

print(f_beta_score(data = test,model = log_reg0))
print(f_beta_score(data = test,model = log_reg3))
```


```{r}
binary_predictions <- ifelse(pred_p[,2] >= 0.2, "true", "false")
sum(binary_predictions=="true")
confusionMatrix(as.factor(binary_predictions), test$Arrest,
                mode = "everything",
                positive="true")
```
## Tuning threshold
```{r}
predicted_probabilities <- pred_p[,2]
  
# Define a range of thresholds to evaluate
thresholds <- seq(0, 1, by = 0.1)

# Initialize a vector to store AUC values for each threshold
auc_values <- numeric(length(thresholds))

# Loop through thresholds, compute AUC for each
for (i in seq_along(thresholds)) {
  binary_predictions <- ifelse(predicted_probabilities >= thresholds[i], "true", "false")
  roc_values <- roc(test$Arrest, pred_p[, "true"])
  auc_values[i] <- auc(roc_values)
}

# Find the threshold that maximizes AUC
optimal_threshold <- thresholds[which.max(auc_values)]

# Display the results
cat("Optimal Threshold:", optimal_threshold, "\n")
cat("Maximum AUC:", max(auc_values), "\n")
```



```{r}
class_weights <- ifelse(train$Arrest == 0, 0.01, 0.99)
log_reg1 <- train(Arrest ~ X.Coordinate + Y.Coordinate + day + hr + 
    Primary.Type, data = train, method = "glm", family = "binomial", trControl = ctrl, metric = "ROC", weights = class_weights)
```

```{r}
print(log_reg1)
```


```{r}
pred1 <- predict(log_reg1, test[,c("X.Coordinate", "Y.Coordinate", "day", "hr", "Primary.Type")], type = "prob")
```

```{r}
# Create a ROC curve object
roc_curve <- roc(test$Arrest, pred1[,2], levels = c(1, 0),direction = ">")

# Plot the ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)

# Add AUC to the plot
auc_value <- auc(roc_curve)
text(0.8, 0.2, paste("AUC =", round(auc_value, 3)), col = "blue", cex = 1.2)
```

## Undersampling

```{r}
train_balanced_under <- ovun.sample(Arrest ~ ., data = train, method = "under", seed = 1)$data
train_balanced_under$Arrest <- as.factor(train_balanced_under$Arrest)
table(train_balanced_under$Arrest)
```


```{r}
log_reg3 <- train(Arrest ~ X.Coordinate + Y.Coordinate + day + hr + 
    Primary.Type, data = train_balanced_under, method = "glm", family = "binomial", trControl = ctrl, metric = "ROC")
```

```{r}
pred3 <- predict(log_reg3, test[,c("X.Coordinate", "Y.Coordinate", "day", "hr", "Primary.Type")], type = "prob")
```


```{r}
binary_predictions <- ifelse(pred3[,2] >= 0.5, "true", "false")
sum(binary_predictions=="true")
# create confusion matrix 
confusionMatrix(as.factor(binary_predictions), test$Arrest,
                mode = "everything",
                positive="true")
```

---
title: "Chicago Crime"
author: "Xin Guan, Vera Hudak, Yuqi Zhang"
date: "2023-11-24"
output:
  pdf_document: default
  html_document: default
---

```{r}
# Packages required
library(lubridate)
library(dplyr)
library(magrittr)
library(tidyverse)
library(ggplot2)
library(caret)
library(pROC)
library(MLmetrics)
library(ROSE)
library(knitr)
#library(sf)
library(spatstat)

library(ggplot2)
library(tidyr)
library(dplyr)
library(readr)
library(e1071)
library(doParallel)
library(mltools)
library(caret)
library(kernlab)
library(ROCR)
library(data.table)

library(geosphere)
```

## Data Processing

```{r}
# Read data
df <- read.csv("OriginalData.csv")
```

### Processing variable 'Date'

```{r}
data <- df %>% select(ID,Date, Primary.Type, Location.Description, Arrest, District)
data %<>% filter(!Primary.Type %in% c("NON-CRIMINAL", "OTHER NARCOTIC VIOLATION", "PUBLIC INDECENCY", "HUMAN TRAFFICKING", "OBSCENITY"))
data$Date <- parse_datetime(data$Date, format = "%m/%d/%Y %I:%M:%S %p")
data %<>%
  mutate(Date = as.POSIXct(Date, format = "%m/%d/%Y %I:%M:%S %p"),
         time = format(as.POSIXct(Date), format = "%H"),
         date = as.Date(Date),
         month = format(as.Date(date, format = "%m/%d/%Y"), "%m"),
         DayofYear = yday(date),
         weekday = weekdays(date))
```

### Processing missing data

```{r}
colSums(is.na(data))
```

We can see that the number of missing values for the variables `X.Coordinate`, `Y.Coordinate`, `Latitude`, and `Longtitude` are exactly the same, we can deduce that the coordinates are calculated from the latitude and longitude, so we don't need to include both pairs of location information. Also since the number of missing value is small compare to the number of data size, we will just eliminate the rows with missing values.

```{r}
data %<>%  na.omit()
```

## Expalnatory Data Analysis

```{r}
data$Primary.Type <- as.factor(data$Primary.Type)
data$time <- as.numeric(data$time)
data$District <- as.factor(data$District)
data$weekday <- as.factor(data$weekday)

data <- data %>% select(ID, Primary.Type, Arrest, District, time, DayofYear, weekday) %>% drop_na()
```

```{r}
# Investigate of variables
df_vis <- df

df_vis$newDate <- mdy_hms(df_vis$Date)
df_vis$WeekDay <- weekdays(df_vis$newDate)
df_vis$DayOfMonth <- day(df_vis$newDate)
df_vis$DayOfYear <- yday(df_vis$newDate)
df_vis$Month <- month(df_vis$newDate, label = TRUE, abbr = FALSE)
df_vis$TimeOfDay <- cut(
  hour(df_vis$newDate),
  breaks= c(-Inf, 5, 12, 17, 20, Inf),
  labels = c("Night", "Early Morning", "Morning", "Afternoon", "Evening"),
  include.lowest = TRUE
)

# Detailed Time
# This format of `Time` variable contains information of hour and minute only
df_vis$newDate <- as.POSIXct(df_vis$newDate, format = "%H:%M:%S")
df_vis$Hour <- hour(df_vis$newDate)
df_vis$Minute <- minute(df_vis$newDate)/60*10
df_vis$Time <- df_vis$Hour + df_vis$Minute/60


# ----------------------------------------------------------------------------
# Components of Dates
# ----------------------------------------------------------------------------
# Weekdays
arrests_by_weekday <- df_vis %>%
  group_by(WeekDay) %>%
  summarise(num_arrests = n())

ggplot(arrests_by_weekday, aes(x = WeekDay, y = num_arrests, fill = WeekDay)) +
  geom_bar(stat = "identity") +
  labs(title = "Number of Arrests by Weekday",
       x = "Weekday",
       y = "Number of Arrests") +
  theme_minimal()

# Month
arrests_by_Month <- df_vis %>%
  group_by(Month) %>%
  summarise(num_arrests = n())

ggplot(df_vis, aes(x = Month, fill = Month)) +
  geom_bar() +
  labs(title = "Number of Arrests by Month",
       x = "Month",
       y = "Number of Arrests") +
  theme_minimal()

# DayOfMonth
arrests_by_DayOfMonth <- df_vis %>%
  group_by(DayOfMonth) %>%
  summarise(num_arrests = n())

ggplot(df_vis, aes(x = DayOfMonth, fill = DayOfMonth)) +
  geom_bar() +
  labs(title = "Number of Arrests by DayOfMonth",
       x = "DayOfMonth",
       y = "Number of Arrests") +
  theme_minimal()

# DayOfYear
arrests_by_DayOfYear <- df_vis %>%
  group_by(DayOfYear) %>%
  summarise(num_arrests = n())

ggplot(df_vis, aes(x = DayOfYear, fill = DayOfYear)) +
  geom_bar() +
  labs(title = "Number of Arrests by DayOfYear",
       x = "DayOfYear",
       y = "Number of Arrests") +
  theme_minimal()


# TimeOfDay
arrests_by_TimeOfDay <- df_vis %>%
  group_by(TimeOfDay) %>%
  summarise(num_arrests = n())

ggplot(df_vis, aes(x = TimeOfDay, fill = TimeOfDay)) +
  geom_bar() +
  labs(title = "Number of Arrests by TimeOfDay",
       x = "TimeOfDay",
       y = "Number of Arrests") +
  theme_minimal()

# hours
arrests_by_hour <- df_vis %>%
  group_by(Hour) %>%
  summarise(num_arrests = n())

ggplot(df_vis, aes(x = Hour, fill = Hour)) +
  geom_bar() +
  labs(title = "Number of Arrests by Hour",
       x = "Hour",
       y = "Number of Arrests") +
  theme_minimal()

# District
arrests_by_dist <- df_vis %>%
  group_by(District) %>%
  summarise(num_arrests = n())

ggplot(df_vis, aes(x = District, fill = District)) +
  geom_bar() +
  labs(title = "Number of Arrests by District",
       x = "District",
       y = "Number of Arrests") +
  theme_minimal()


# ----------------------------------------------------------------------------
# Relations between `Primary.Type` and `TimeOfDay` in a specific `Weekday`
# ----------------------------------------------------------------------------
# Choose a specific weekday (e.g., "Monday")
selected_weekday <- "Monday"
# Filter the data for the selected weekday
filtered_data <- df_vis %>% filter(WeekDay == selected_weekday)

# Summary table with the count of crimes for each combination of `Primary.Type` and `TimeOfDay`
crime_time_counts <- filtered_data %>%
  group_by(Primary.Type, TimeOfDay) %>%
  summarise(Count = n())

ggplot(crime_time_counts, aes(x = TimeOfDay, y = Primary.Type, fill = Count)) +
  geom_tile() +
  scale_fill_viridis_c() +
  labs(title = paste("Primary.Type and TimeOfDay Relationship on", selected_weekday),
       x = "Time of the Day",
       y = "Primary.Type",
       fill = "Crime Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "right")

```

## Feature Selection

Our first task is to predict whether arrest or not given time, location, and the crime type.

```{r}
data %<>% filter(District != "31")
sum(data$District=="31")
```

## Define Cross-validation

```{r}
# Define a 5-fold cross validation
ctrl <- trainControl(method = "cv", number = 5, summaryFunction = twoClassSummary, classProbs = TRUE)
```

## Imbalance Data Experiments with a Baseline Model

```{r}
# Separate positive and negative classes
true_class <- data %>% filter(Arrest == "true")
false_class <- data %>% filter(Arrest == "false")

# Set the desired ratio of positive to negative samples
desired_positive_ratio <- 0.05

# Calculate the number of positive samples needed for downsampling
num_true_samples <- 0.05*nrow(false_class) / (1 - desired_positive_ratio)

# Randomly sample positive samples
true_class_downsampled <- true_class %>% sample_n(num_true_samples, replace = FALSE, seed = 42)

# Combine positive and downsampled negative samples
downsampled_dataset <- bind_rows(false_class, true_class_downsampled)

# Shuffle the dataset to mix positive and negative samples
set.seed(42)
downsampled_dataset <- downsampled_dataset[sample(nrow(downsampled_dataset)), ]

sum(downsampled_dataset[,"Arrest"]=="true")/dim(df)[1]
```

```{r}
#use 80% of dataset as training set and 20% as test set 
variables_to_convert <- c("Arrest", "Primary.Type", "weekday")
imbalanced_train <- downsampled_dataset %>% dplyr::sample_frac(0.80)
imbalanced_train[, variables_to_convert] <- lapply(imbalanced_train[, variables_to_convert], as.factor)
imbalanced_test  <- dplyr::anti_join(downsampled_dataset, imbalanced_train, by = 'ID')
imbalanced_test[, variables_to_convert] <- lapply(imbalanced_test[, variables_to_convert], as.factor)
imbalanced_train %<>% select(-"ID")
imbalanced_test %<>% select(-"ID")
```

```{r}
base_m <- train(Arrest ~ District + DayofYear + time + 
    Primary.Type, data = imbalanced_train, method = "glm", family = "binomial", trControl = ctrl, metric = "ROC")
```

```{r}
pred <- predict(base_m, imbalanced_test[,c("District", "DayofYear", "time", "Primary.Type")], type = "prob")
```

```{r}
binary_predictions <- ifelse(pred[,2] >= 0.5, "true", "false")
# create confusion matrix 
confusionMatrix(as.factor(binary_predictions), imbalanced_test$Arrest,
                mode = "everything",
                positive="true")
```

```{r}
#over sampling
train_balanced_over <- ovun.sample(Arrest ~ District + DayofYear + time + 
    Primary.Type, data = imbalanced_train, method = "over")$data
train_balanced_over$Arrest <- as.factor(train_balanced_over$Arrest)
train_balanced_under <- ovun.sample(Arrest ~ District + DayofYear + time + 
    Primary.Type, data = imbalanced_train, method = "under")$data
train_balanced_under$Arrest <- as.factor(train_balanced_under$Arrest)
#train.rose <- ROSE(Arrest ~ District + DayofYear + time + Primary.Type, data = imbalanced_train)$data
#train.rose$Arrest <- as.factor(train.rose$Arrest)
#table(train.rose$Arrest)
table(train_balanced_over$Arrest)
table(train_balanced_under$Arrest)
```

```{r}
base_m_under <- train(Arrest ~District + DayofYear + time + Primary.Type, data = train_balanced_under, method = "glm", family = binomial, trControl = ctrl, metric = "ROC")
base_m_over <- train(Arrest ~ District + DayofYear + time + Primary.Type, data = train_balanced_over, method = "glm", family = "binomial", trControl = ctrl, metric = "ROC")
#base_m_rose <- train(Arrest ~ District + DayOfYear + Hour + Primary.Type, data = train.rose, method = "glm", family = "binomial", trControl = ctrl, metric = "ROC")
```

```{r}
pred_under <- predict(base_m_under, imbalanced_test[,c("District", "DayofYear", "time", "Primary.Type")], type = "prob")
pred_over <- predict(base_m_over, imbalanced_test[,c("District", "DayofYear", "time", "Primary.Type")], type = "prob")
#pred_rose <- predict(base_m_rose, imbalanced_test[,c("District", "DayofYear", "time", "Primary.Type")], type = "prob")
```

```{r}
# Create a ROC curve object for each prediction
roc_curve <- pROC::roc(imbalanced_test$Arrest, pred[,2])
#the roc function name is used in several packages, `pROC::roc` is used to ensure the roc function is from pROC package.
roc_curve_under <- pROC::roc(imbalanced_test$Arrest, pred_under[,2])
roc_curve_over <- pROC::roc(imbalanced_test$Arrest, pred_over[,2])
#roc_curve_rose <- pROC::roc(imbalanced_test$Arrest, pred_rose[,2])

# Plot the first ROC curve
plot(roc_curve, col = "blue", lwd = 2, main = "ROC Curve")

# Add AUC to the plot for the first curve
auc_value <- pROC::auc(roc_curve)
text(0.8, 0.2, paste("AUC =", round(auc_value, 3)), col = "blue", cex = 1.2)

# Add the other ROC curves to the plot
lines(roc_curve_under, col = "red", lwd = 2)
lines(roc_curve_over, col = "green", lwd = 2)
#lines(roc_curve_rose, col = "purple", lwd = 2)

# Add AUC values for the other curves
text(0.8, 0.15, paste("AUC =", round(pROC::auc(roc_curve_under), 3)), col = "red", cex = 1.2)
text(0.8, 0.1, paste("AUC =", round(pROC::auc(roc_curve_over), 3)), col = "green", cex = 1.2)
#text(0.8, 0.05, paste("AUC =", round(pROC::auc(roc_curve_rose), 3)), col = "purple", cex = 1.2)

legend("bottomright", legend = c("Original", "Under-sampled", "Over-sampled"),
       col = c("blue", "red", "green"), lty = 1, lwd = 2)
```

Given the current highly imbalanced nature of the data, the effectiveness of comparing models using the AUC curve diminishes. It's advisable to explore alternative evaluation metrics. The provided code below computes the F-$\beta$ score, an generalization of the F-1 score, the F-1 score is included in the output of `confusionMatrix()` function. The parameter $\beta \geq 0$ is the weight assigned to recall, in the case, we should choose $\beta>1$, so we prioritize the recall.

## F-beta Score

```{r}
f_beta_score <- function(X, y, model, beta, threshold=0.5) {
  predictions <- predict(model, X, type = "prob")[,2]
  predicted_classes <- ifelse(predictions > threshold, "true", "false")
  predicted_classes <- as.factor(predicted_classes)
  pr <- confusionMatrix(data = predicted_classes, reference = y, 
                        mode = "everything", positive="true")

  precision <- as.numeric(pr$byClass["Precision"])
  recall <- as.numeric(pr$byClass["Recall"])

  f_beta <- ((1 + beta^2) * precision * recall) / (beta^2 * precision + recall)
  return(f_beta)
}
```

```{r}
f2 <- f_beta_score(X=imbalanced_test[,c("District", "DayofYear", "time", "Primary.Type")], y=imbalanced_test$Arrest,model=base_m,beta=5)
f2_under <- f_beta_score(X=imbalanced_test[,c("District", "DayofYear", "time", "Primary.Type")], y=imbalanced_test$Arrest,model=base_m_under,beta=5)
f2_over <- f_beta_score(X=imbalanced_test[,c("District", "DayofYear", "time", "Primary.Type")], y=imbalanced_test$Arrest,model=base_m_over,beta=5)
print(c(f2,f2_under,f2_over))
```

## Train Test Split

```{r}
#use 80% of dataset as training set and 20% as test set 
variables_to_convert <- c("Arrest", "Primary.Type", "weekday")
train <- data %>% dplyr::sample_frac(0.80)
train[, variables_to_convert] <- lapply(train[, variables_to_convert], as.factor)
test  <- dplyr::anti_join(data, train, by = 'ID')
test[, variables_to_convert] <- lapply(test[, variables_to_convert], as.factor)
train %<>% select(-"ID")
test %<>% select(-"ID")
```

## Predict Probability of Arrest

### Logistic Regression Model

```{r}
# Define a 5-fold cross validation
ctrl <- trainControl(method = "cv", number = 5, summaryFunction = twoClassSummary, classProbs = TRUE)
```

-   base

```{r}
base_m <- train(Arrest ~ District + DayofYear + time + Primary.Type, 
                data = train, method = "glm", family = "binomial", trControl = ctrl, metric = "ROC")
```

```{r}
pred <- predict(base_m, test[,c("District", "DayofYear", "time", "Primary.Type")], type = "prob")
```

```{r}
binary_predictions <- ifelse(pred[,2] >= 0.5, "true", "false")
# create confusion matrix 
confusionMatrix(as.factor(binary_predictions), test$Arrest,
                mode = "everything",
                positive="true")
roc_curve <- pROC::roc(test$Arrest, pred[,2],levels = c("true", "false"),direction = ">")
plot(roc_curve, main = "ROC Curve for Baseline Model", col = "blue", lwd = 2)

auc_curve <- pROC::auc(roc_curve)
text(0.8, 0.2, paste("AUC =", round(auc_curve, 3)), col = "blue", cex = 1.2)
```

-   improvement of baseline 1

```{r}
logistic_im_1 <- train(Arrest ~ District + DayofYear + weekday + time + Primary.Type, 
                       data = train, method = "glm", family = "binomial", trControl = ctrl, metric = "ROC")

# Cannot use `Time` - result in multicollineararity
# DayOfMonth and Month 

pred_im_1 <- predict(logistic_im_1, test[,c("District", "DayofYear", "weekday", "time", "Primary.Type")], type = "prob")

binary_predictions_im_1 <- ifelse(pred_im_1[,2] >= 0.5, "true", "false")
# create confusion matrix 
confusionMatrix(as.factor(binary_predictions_im_1), test$Arrest,
                mode = "everything",
                positive="true")

roc_1 <- pROC::roc(test$Arrest, pred_im_1[,2], levels = c("true", "false"),direction = ">")
plot(roc_1, main = "ROC Curve", col = "blue", lwd = 2)

auc_1 <- pROC::auc(roc_1)
text(0.8, 0.2, paste("AUC =", round(auc_1, 3)), col = "blue", cex = 1.2)

```

-   improvement of baseline 2

```{r}
train$time_t <- train$time^2
test$time_t <- test$time^2
train$DayofYear_t <- train$DayofYear^2
test$DayofYear_t <- test$DayofYear^2

logistic_im_2 <- train(Arrest ~ District + DayofYear_t + weekday + time_t + Primary.Type, 
                       data = train, method = "glm", family = "binomial", trControl = ctrl, metric = "ROC")

# Cannot use `Time` - result in multicollineararity

pred_im_2 <- predict(logistic_im_2, test[,c("District", "DayofYear_t", "weekday", "time_t", "Primary.Type")], type = "prob")

binary_predictions_im_2 <- ifelse(pred_im_2[,2] >= 0.5, "true", "false")
# create confusion matrix 
confusionMatrix(as.factor(binary_predictions_im_2), test$Arrest,
                mode = "everything",
                positive="true")

roc_2 <- pROC::roc(test$Arrest, pred_im_2[,2], levels = c("true", "false"),direction = ">")
plot(roc_2, main = "ROC Curve", col = "blue", lwd = 2)

auc_2 <- pROC::auc(roc_2)
text(0.8, 0.2, paste("AUC =", round(auc_2, 3)), col = "blue", cex = 1.2)
```

## Support Vector Machine

Next, we use SVM to predict the outcome of a crime (arrest or no arrest) using the variables ``Primary.Type``, ``Disctrict``, ``time``, ``DayofYear`` and ``weekday``. As the relationship between outcome and variables is unclear, we use SVM with radial basis kernel. For SVM, the variables need to be one hot encoded.

```{r}
# One hot encode data
data_svm <- data %>% select(-ID)
data_svm <- as.data.table(data_svm)
data_svm <- one_hot(data_svm)

```

Support Vector Machines (SVMs) face challenges with large datasets due to their cubic time complexity during training, making them computationally expensive as the dataset size increases. Additionally, SVMs often require storing the entire training dataset in memory, which can be impractical for large datasets, leading to reliance on disk storage and slowing down the training process. Furthermore, SVMs exhibit scalability issues, as the optimization problem they solve is quadratic in the number of samples, diminishing their efficiency for large-scale datasets. So for when fitting our models, we will use a random sample from our data set, using 3 types of sampling methods.

1. Proportional sampling: this sampling methods generates a sample where the proportion of each classes emulates the original data set.

We take 5% of the data to train our model on, keeping the class proportions as in the original data set and use it to fit the SVM.

```{r}
# Take proportional training sample 
trainIndex <- createDataPartition(data_svm$Arrest, p = .05, list = TRUE)
train <- data_svm[trainIndex$Resample,]
train %>% dplyr::count(Arrest)

```


```{r}
# CV seeds
seeds <- vector(mode = "list", length = 6)
for(i in 1:6) seeds[[i]] <- sample.int(n=1000, 3)

# CV function
control <- trainControl(method = 'cv', number = 5, allowParallel = TRUE, seeds=seeds)

```


```{r}
# SVM with proportional sample
cl <- makePSOCKcluster(detectCores() - 1)

registerDoParallel(cl)

svm.model <- train(Arrest ~ ., data = train, trControl = control, method = 'svmRadial', family = binomial(), allowParallel = TRUE)

stopCluster(cl)

```


```{r}
# Propotional test data
sampIndex <- createDataPartition(data_svm$Arrest, p = .025, list = TRUE)

test <- data_svm[sampIndex$Resample,]

# Confusion matrix
test$Arrest <- as.factor(test$Arrest)

conf_matrix1 <- confusionMatrix(data = predict(svm.model, newdata = test), reference = test$Arrest, positive = 'true', mode = "everything")

conf_matrix1
```

2. Downsampling : downsampling is a mechanism that reduces the count of training samples falling under the majority class, by randomly removing instances from the majority class until the class distribution is balanced. This method is straightforward but may discard potentially valuable information.

```{r}
# Down sample the dataset
data_svm$Arrest = as.factor(data_svm$Arrest)

down_sample <- downSample(x = data_svm, y = data_svm$Arrest)

down_sample %>% count(Arrest)
```

```{r}
# Take random tarining data from down sampled data
trainIndexD <- createDataPartition(down_sample$Arrest, p = nrow(train)/nrow(down_sample), list = TRUE)

train2 <- down_sample[trainIndexD$Resample,] %>% select(-Class)

train2 %>% count(Arrest)

```

```{r}
# Fit SVM using down sampling
cl <- makePSOCKcluster(detectCores() - 1)

registerDoParallel(cl)

svm.model2 <- train(Arrest ~ ., data = train2, trControl = control, method = 'svmRadial', family = binomial(), allowParallel = TRUE)

stopCluster(cl)

```

```{r}
# Test data
sampIndex <- createDataPartition(data_svm$Arrest, p = .025, list = TRUE)

test <- data_svm[sampIndex$Resample,]

# Confusion matrix
test$Arrest <- as.factor(test$Arrest)

conf_matrix2 <- confusionMatrix(data = predict(svm.model2, newdata = test), reference = test$Arrest, positive = 'true', mode = "everything")

conf_matrix2
```

3. Upsampling: this is a technique used in machine learning to address imbalanced datasets. Upsampling involves increasing the number of instances in the minority class to balance it with the number of instances in the majority class by randomly duplicating instances from the minority class until the class distribution is balanced. This method may lead to overfitting since it replicates existing instances.


```{r}
# Generate up sampled dataset
up_sample <- upSample(x = data_svm, y = data_svm$Arrest)

up_sample %>% count(Arrest)

# Up sampled training data
trainIndexD <- createDataPartition(up_sample$Arrest, p = nrow(train)/nrow(up_sample), list = TRUE)

train3 <- up_sample[trainIndexD$Resample,] %>% select(-Class)

train3 %>% count(Arrest)

```

```{r}
# Fit SVM with upsampling
cl <- makePSOCKcluster(detectCores() - 1)

registerDoParallel(cl)

svm.model3 <- train(Arrest ~ ., data = train3, trControl = control, method = 'svmRadial', family = binomial(), allowParallel = TRUE)

stopCluster(cl)

# Test data

sampIndex <- createDataPartition(data_svm$Arrest, p = .025, list = TRUE)

test <- data_svm[sampIndex$Resample,]

test$Arrest <- as.factor(test$Arrest)

# Confucion matrix
conf_matrix3 <- confusionMatrix(data = predict(svm.model3, newdata = test), reference = test$Arrest, positive = 'true', mode = "everything")

conf_matrix3

```


## Predict Number of Cases withing Radius of 5 km



## Separate dataset by month

```{r}
# Split the data into a list of data frames by month
months_list <- split(data, data$month)
# Access subsets using names, e.g., months_list$"01" for January
```

```{r}
# Function to calculate distance in kilometers between two points
calculate_distance <- function(lat1, lon1, lat2, lon2) {
  distVincentySphere(c(lon1, lat1), c(lon2, lat2))
}

# Function to count points within a specified radius (in kilometers) of the data point
count_points_within_radius <- function(subset_data, radius_km) {
  counts <- sapply(1:nrow(subset_data), function(i) {
    distances <- sapply(1:nrow(subset_data), function(j) {
      calculate_distance(subset_data$Latitude[i], subset_data$Longitude[i],
                         subset_data$Latitude[j], subset_data$Longitude[j])
    })
    sum(distances <= radius_km)
  })
  return(counts)
}

# Specify the radius of the circle (in kilometers)
radius_km <- 5
```

## Count the crime number for January

```{r}
# Use the count_points_within_radius function on the January subset
months_list$"01"$CountWithinRadius <- count_points_within_radius(months_list$"01", radius_km)
data_Jan <- months_list$"01"
```

## Regression

```{r}
# Set the seed for reproducibility
set.seed(123)

# (70% train, 30% test)
index <- createDataPartition(data_Jan$CountWithinRadius, p = 0.7, list = FALSE)

# Split the data into training and testing sets
Jan_train <- data_Jan[index, ]
Jan_test <- data_Jan[-index, ]

# Set up the control parameters
Jan_ctrl <- trainControl(method = "cv", number = 10)

# Perform cross-validation
Jan_reg <- train(CountWithinRadius ~ Latitude + Longitude + Primary.Type, data = Jan_train, method = "lm", trControl = Jan_ctrl)

# Print cross-validation results
print(Jan_reg)

# Predictions
Jan_pre <- predict(Jan_reg, newdata = Jan_test)


```

## Analysis of the residuals / MAE MSE RMSE / pred values
```{r}
# Extract the residuals from the train object
residuals <- residuals(Jan_reg)

# Residuals vs. Fitted Values Plot
plot(x = predict(Jan_reg), y = residuals, xlab = "Fitted Values", ylab = "Residuals", main = "Residuals vs. Fitted Values")

# Add a horizontal line at y = 0 for reference
abline(h = 0, col = "red", lty = 2)


# Calculate evaluation metrics
mae <- mean(abs(Jan_pre - Jan_test$CountWithinRadius))
mse <- mean((Jan_pre - Jan_test$CountWithinRadius)^2)
rmse <- sqrt(mse)

# Print evaluation metrics
print(paste("MAE:", mae))
print(paste("MSE:", mse))
print(paste("RMSE:", rmse))


# Create a scatter plot of true vs. predicted values
plot(Jan_test$CountWithinRadius, Jan_pre,
     xlab = "True Values", ylab = "Predicted Values",
     main = "True vs. Predicted Values", pch = 16)
abline(0, 1, col = "red", lty = 2)  # Diagonal line for reference


```


```{r}
data_Jan <- read.csv("data_Jan.csv")
data_Jan <- read.csv("data_Feb.csv")
data_Jan <- read.csv("data_Mar.csv")
data_Jan <- read.csv("data_Apr.csv")
data_Jan <- read.csv("data_May.csv")
data_Jan <- read.csv("data_Jan.csv")
```


NOTES - Yuqi:

Note that this is only for January, it will take a very long time to count the number of crimes that happened within the circle.

Besides, since it takes about 4-5 hours to get the crime number within 5km in a particular month, here I also uploaded the datasets `data_Jan.csv` to `data_Jun.csv` (you can find it in `Github`, cuz I am going to the airport I stopped at the dataset in June), for you to perform regression (like linear regression or Poisson - I just tried `lm`).
